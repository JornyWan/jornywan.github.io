---
permalink: /
title: "Cheng Wan"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi there! I'm Cheng Wan, a second-year Master's student in Electrical and Computer Engineering (ECE) at Georgia Tech.

Prior to pursuing my Master's degree, I conducted research in the biomedical field at the Shenzhen Institute of Advanced Technology of the Chinese Academy of Science ([SIAT, CAS](https://english.siat.ac.cn/)) supervised by Dr. [Dan Wu](https://www.bit-siat.com/en/index.php?s=/Show/index/cid/12/id/16.html) and Professor [Ye Li](http://www.bit-siat.com/en/index.php?s=/Show/index/cid/10/id/2.html), focusing on blood pressure measurement.

I have a strong interest in applying AI within the area of biomedicine (**Healthcare**). My research interests revolve around the application of Machine Learning and Deep Learning techniques, particularly in the domains of **Computer Vision**.

I am now a research assistant in HuLab at [HuLab](https://www.nursing.emory.edu/initiatives/center-for-data-science) at [Emory](), still research on biomedical engineer area supervised by Professor [Ran Xiao]([https://www.nursing.emory.edu/initiatives/center-for-data-science](https://www.nursing.emory.edu/faculty-staff/ran-xiao)) and [Xiao Hu](https://www.nursing.emory.edu/faculty-staff/xiao-hu). 

I am enthusiastic about further exploring these areas and enhancing my expertise. If you're interested in connecting, please feel free to contact me at **c.wan@gatech.edu**.

For more details, you can view my [Curriculum Vitae](pdfs/mycv.pdf).


**I am actively looking for a Research Intern position in Tech companies!**

# üî• News
- \[24.06\] üéâ I will give an **Oral Presentation** at CVPR 2024, NTIRE Workshop at June 17th, see you in **Seattle**!
- \[24.04\] üéâ Our [paper](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Wan_Swift_Parameter-free_Attention_Network_for_Efficient_Super-Resolution_CVPRW_2024_paper.html) is accepted to CVPR 2024 Workshop!
- \[24.03\] üèÜ We won 2 **championships**, a **runner-up** and a **3rd place**  in CVPR 2024 NTIRE ([ESR](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Ren_The_Ninth_NTIRE_2024_Efficient_Super-Resolution_Challenge_Report_CVPRW_2024_paper.html), [SRx4](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Chen_NTIRE_2024_Challenge_on_Image_Super-Resolution_x4_Methods_and_Results_CVPRW_2024_paper.html), [RawSR](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Conde_Deep_RAW_Image_Super-Resolution._A_NTIRE_2024_Challenge_Survey_CVPRW_2024_paper.html)) and AIS ([RTSR](https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Conde_Real-Time_4K_Super-Resolution_of_Compressed_AVIF_Images._AIS_2024_Challenge_CVPRW_2024_paper.html))
  

# üìù Publications
(\* means co-first author / equal contributions)

- [Due to the double-blind rules of the journal, this information is not disclosed.](https://jornywan.github.io/) \
anonymous author, **C. Wan**\*, anonymous author, anonymous author, anonymous author\\
OJEMB 2024 (Under Review) 

- [Due to the double-blind rules of the conference, this information is not disclosed.](https://jornywan.github.io/) \
**C. Wan**\*, anonymous author, anonymous author, anonymous author, anonymous author\\
BHI 2024 (Under Review) 

- [Swift Parameter-free Attention Network for Efficient Super-Resolution](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Wan_Swift_Parameter-free_Attention_Network_for_Efficient_Super-Resolution_CVPRW_2024_paper.html) \
**C. Wan**\*, H. Yu\*, Z. Li\*, Y. Chen, Y. Zou, Y. Liu, X. Yin, K. Zuo\\
CVPR 2024 Workshop (Winner Award at NTIRE) (Oral) 

- [Real-Time Image Segmentation via Hybrid Convolutional-Transformer Architecture Search](https://arxiv.org/abs/2403.10413) \
H. Yu, **C. Wan**, M. Liu, D. Chen, B. Xiao, X. Dai\\
Preprint 

- [Unveiling Linear Mode Connectivity of Re-basin from Neuron Distribution Perspective](https://openreview.net/pdf?id=RzOm9oOSzm) \
Z. Li\*, Z. Li\*, **C. Wan**\*, M. Wu\*, C. Wu \\
Preprint 

- TabNet: Muiti-Scenario Personalized Time Series Attention-based Blood Pressure Forecasting Network \
**C. Wan**, C. Xie, L. Liu, D. Wu, and Y. Li, _Senior Member, IEEE_ \\
Under Review

- [Effects of Pulse Transit Time and Pulse Arrival Time on Cuff-less Blood Pressure Estimation: A Comparison Study with Multiple Experimental Interventions](https://arinex.com.au/EMBC/pdf/full-paper_1245.pdf) \
C. Xie, **C. Wan**, Y. Wang, J. Song, D. Wu, and Y. Li, _Senior Member, IEEE_ \\
EMBC 2023 

# üèÜ Challenges
- CVPR 2024: NTIRE Efficient Super-Resolution Challenge (ESR) \
**1st place** [Report](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Ren_The_Ninth_NTIRE_2024_Efficient_Super-Resolution_Challenge_Report_CVPRW_2024_paper.html)

- CVPR 2024: NTIRE Image Super-Resolution (√ó4) Challenge (SRx4) \
**1st place** [Report](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Chen_NTIRE_2024_Challenge_on_Image_Super-Resolution_x4_Methods_and_Results_CVPRW_2024_paper.html)

- CVPR 2024: NTIRE Raw Image Super-Resolution Challenge (RawSR) \
**2nd place** [Report](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Conde_Deep_RAW_Image_Super-Resolution._A_NTIRE_2024_Challenge_Survey_CVPRW_2024_paper.html)

- CVPR 2024: AIS Real-Time Image Super-Resolution Challenge (RTSR) \
**3rd place** [Report](https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Conde_Real-Time_4K_Super-Resolution_of_Compressed_AVIF_Images._AIS_2024_Challenge_CVPRW_2024_paper.html)

- ICCV 2023: The First Visual Object Tracking Segmentation Challenge (VOTS) \
**3rd in Robust track** [Report](https://openaccess.thecvf.com/content/ICCV2023W/VOTS/papers/Kristan_The_First_Visual_Object_Tracking_Segmentation_VOTS2023_Challenge_Results_ICCVW_2023_paper.pdf)\\

# üìù Open-Source Projects
- [RITA: A Real-time Interactive Talking Avatars Framework](https://arxiv.org/abs/2406.13093) \
**C. Wan**\*, C. Lin\*, Y. Cao\* \\
Preprint (CVPR 2024 Demo Track)

- MCD-Net: Towards Real-World RGB-D Video Inpainting \
J. Hou, **C. Wan** \\
Our contribution can be briefly summarized as a new model **MCD-Net** and a new dataset **VID Dataset**. \\
[Project](https://github.com/JCATCV/MCD-Net) | [Dataset](https://pan.baidu.com/s/1q9ys6ITxQgtfgYltQbdyvA?pwd=lor3) (**Welcome to use our VID Dataset**)

- Learning Chess from Transformer-Based Language Model \
**C. Wan**, N. Wang\*, C. Deng\* \\
Chess can be a testbed for evaluating language models on world state tracking. \\
[Project](https://github.com/JornyWan/learning-chess-blindfolded)

# üéñ Honors and Awards
- *2022.08* Merit Student Scholarship, Georgia Institute of Technology. 
- *2022.07* Outstanding Scholarship (Top1), Nanchang Hangkong University.
- *2021.07* Outstanding Scholarship (Top10), Nanchang Hangkong University.

# üìñ Educations
- *2022.08 - now*, Master's degree, Georgia Institute of Technology.
- *2021.11 - 2022.07*, Visiting Student, SIAT, Chinese Academic of Science.
- *2018.09 - 2022.07*, Bachelor's degree, Nanchang Hangkong University.

# üíª Internships
- *2021.11 - 2022.07*, [SIAT, CAS](https://english.siat.ac.cn/), China.
- *2021.06 - 2021.08*, [ECCOM](https://www.eccom.com/en/), China.

# üí¨ Fun Facts
- üö£üèº‚Äç‚ôÇÔ∏è GT varsity men rowing team, I love rowing, hiking and playing all kinds of balls sports.
- üé§ I used to hold 3 livehouse shows for singing, more than 400 people were there.
- üèÜ I won 3rd place in the Intel Cup of CSGO in China.

Thank you for taking the time to learn about me!





